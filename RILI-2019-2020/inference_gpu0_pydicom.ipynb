{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "from torchvision import transforms as xfms\n",
    "\n",
    "from model import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HU_CLIP = [-900, 100]\n",
    "IMG_SIZE = 512\n",
    "NET_SIZE = 448\n",
    "MEAN = 0.36\n",
    "STD = 0.42\n",
    "XFM_COMP = xfms.Compose([\n",
    "    xfms.ToTensor(),\n",
    "    xfms.Resize((IMG_SIZE, IMG_SIZE), antialias=True),\n",
    "    xfms.CenterCrop((NET_SIZE, NET_SIZE)),\n",
    "    xfms.Normalize(MEAN, STD)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(patientDicomPath, xfmComp=XFM_COMP):\n",
    "    # Load all the DICOM files from a single folder into a list of 3D images and return the numpy array by simpleITK\n",
    "    # reader = sitk.ImageSeriesReader()\n",
    "    # dicom_names = reader.GetGDCMSeriesFileNames(patientDicomPath)\n",
    "    # reader.SetFileNames(dicom_names)\n",
    "    # img_itk = reader.Execute()\n",
    "    # img_3dnp = sitk.GetArrayFromImage(img_itk)\n",
    "\n",
    "    dicom_files = list(Path(patientDicomPath).rglob('*.dcm'))\n",
    "    slices = [pydicom.dcmread(file) for file in dicom_files]\n",
    "    slices.sort(key=lambda x: int(x.InstanceNumber))\n",
    "    img_3d = np.stack([s.pixel_array for s in slices])\n",
    "    img_3d = img_3d * slices[0].RescaleSlope + slices[0].RescaleIntercept\n",
    "    img_3dnp = img_3d.copy()\n",
    "\n",
    "    slice_filter = (999, 0)\n",
    "    for i, img in enumerate(img_3dnp):\n",
    "        pc, _ = cv2.findContours(np.array(img > -150, np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        sapc = sorted(map(cv2.contourArea, pc), reverse=True)\n",
    "        if sapc[1] > 1e4 or sapc[2] > 1.5e3:\n",
    "            slice_filter = (min(slice_filter[0], i), max(slice_filter[1], i))\n",
    "\n",
    "    img_3dnp = img_3dnp[slice_filter[0]:slice_filter[1]]\n",
    "    img_3dnp = np.clip(img_3dnp, HU_CLIP[0], HU_CLIP[1])  # clip HU values\n",
    "    img_3dnp = img_3dnp.astype(np.float32)\n",
    "    img_3dnp = (img_3dnp - HU_CLIP[0]) / (HU_CLIP[1] - HU_CLIP[0])  # normalize to [0, 1]\n",
    "\n",
    "    img_4dnp = torch.stack([XFM_COMP(img_3dnp[i]) for i in range(img_3dnp.shape[0])])\n",
    "\n",
    "    return img_4dnp, img_3d, slice_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, input4Dtensor, batchSize=8):\n",
    "    torch.cuda.set_device(0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device\", torch.cuda.current_device(), torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "    net.to(device).eval()\n",
    "    with torch.no_grad():\n",
    "        output = torch.cat(\n",
    "            [net(input4Dtensor[i:i + batchSize].to(device)) for i in range(0, input4Dtensor.shape[0], batchSize)], dim=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(output, threshold=0.5):\n",
    "    output = output.cpu()\n",
    "    output = torch.sigmoid(output)\n",
    "\n",
    "    msk_3d = np.zeros((output.shape[0], IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    diff_size = (IMG_SIZE - NET_SIZE) // 2\n",
    "    for i, pp in enumerate(output):\n",
    "        pc, _ = cv2.findContours(np.array(pp[0] > threshold, np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        for c in pc:\n",
    "            if cv2.contourArea(c) > 500:\n",
    "                cv2.fillPoly(msk_3d[i], [c + diff_size], 1)\n",
    "\n",
    "    return msk_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img3D, msk3D, show=False, save=False, save_path=None, window=(-1000, 200)):\n",
    "    pos_pairs = []\n",
    "    for i, (x, y) in enumerate(zip(img3D, msk3D)):\n",
    "        if np.sum(y) > 0:\n",
    "            pos_pairs.append((i, x, y))\n",
    "\n",
    "    d = len(pos_pairs)\n",
    "    di, dj = [[j, j + i] for j in range(d) for i in range(2) if j**2 + i * j > d][0]\n",
    "    fig = plt.figure(figsize=(min(dj * 4, 24), min(di * 4, 24)))\n",
    "    for i, (idx, img, msk) in enumerate(pos_pairs):\n",
    "        ax = fig.add_subplot(di, dj, i + 1)\n",
    "        ax.imshow(img, cmap='bone', vmin=window[0], vmax=window[1])\n",
    "        pc, _ = cv2.findContours(np.array(msk > .5, np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        for c in pc:\n",
    "            plt.plot(c[:, 0, 0], c[:, 0, 1], color=\"yellow\")\n",
    "        ax.set_title(f\"slice {idx}, area {np.sum(msk)}\")\n",
    "        # pc, _ = cv2.findContours(np.array(img > -150, np.uint8) , cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        # pc = sorted(pc, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "        # for c in pc:\n",
    "        #     plt.plot(c[:, 0, 0], c[:, 0, 1], color=\"red\")\n",
    "        # ax.set_title(f\"slice {idx}, {cv2.contourArea(pc[0])}\\n{[cv2.contourArea(c) for c in pc[1:4]]}\")\n",
    "        ax.axis('off')\n",
    "    if save and save_path is not None:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(net=UNet(encChannels=(1, 16, 32, 64), outSize=(NET_SIZE, NET_SIZE)),\n",
    "              weightPath=None,\n",
    "              patientDicomPath=\"RP-2019-46p111ct/000218422H_20191128\",\n",
    "              batchSize=8,\n",
    "              window=(-1000, 200),\n",
    "              savePath=None):\n",
    "    if weightPath is not None:\n",
    "        state_dict = torch.load(weightPath, map_location=torch.device('cpu'))\n",
    "        moderfied_state_dict = {}\n",
    "        for key, value in state_dict.items():\n",
    "            if key.startswith('module.'):  # 删除\"module.\"前缀\n",
    "                new_key = key[7:]\n",
    "            else:\n",
    "                new_key = key\n",
    "            moderfied_state_dict[new_key] = value\n",
    "        del state_dict\n",
    "        net.load_state_dict(moderfied_state_dict)\n",
    "\n",
    "    # input4Dtensor, img_itk, slice_filter = preprocess(patientDicomPath)\n",
    "    input4Dtensor, img_3d, slice_filter = preprocess(patientDicomPath)\n",
    "    output = evaluate(net, input4Dtensor, batchSize)\n",
    "    mask = postprocess(output)\n",
    "\n",
    "    # draw(sitk.GetArrayFromImage(img_itk)[slice_filter[0]:slice_filter[1]], mask, show=True, save=savePath is not None, save_path=savePath, window=window)\n",
    "    draw(img_3d[slice_filter[0]:slice_filter[1]], mask, show=True, save=savePath is not None, save_path=savePath, window=window)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = inference(\n",
    "    weightPath='0.0244_109.pth',\n",
    "    patientDicomPath='D:/irene2023_share/20230711/001163511D/1.2.840.113817.20230411120100.1200116351194.85938009287')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
