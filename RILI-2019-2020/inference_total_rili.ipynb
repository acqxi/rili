{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Callable\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "from torchvision import transforms as xfms\n",
    "\n",
    "from totalsegmentator.python_api import totalsegmentator\n",
    "from totalsegmentator.dicom_io import dcm_to_nifti\n",
    "\n",
    "from model import UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HU_CLIP = (-1000, 200)\n",
    "IMG_SIZE = 512\n",
    "NET_SIZE = 448\n",
    "MEAN = 0.36\n",
    "STD = 0.42\n",
    "BATCH_SIZE = 8\n",
    "XFM_COMP = xfms.Compose([\n",
    "    xfms.ToTensor(),\n",
    "    xfms.Resize((IMG_SIZE, IMG_SIZE), antialias=True),\n",
    "    xfms.CenterCrop((NET_SIZE, NET_SIZE)),\n",
    "    xfms.Normalize(MEAN, STD)\n",
    "])\n",
    "\n",
    "GPU_NUMBER = 0\n",
    "THRESHOLD = 0.5\n",
    "SMOOTH_AREA = 150\n",
    "\n",
    "NET = UNet(outSize=(NET_SIZE, NET_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toITK(pixels: np.ndarray, savePath: Path, affine: dict):\n",
    "    # pixels: 3D numpy array\n",
    "    # path: save path\n",
    "    # infos: dict\n",
    "    itk = sitk.GetImageFromArray(pixels)\n",
    "    itk.SetSpacing(affine['spacing'])\n",
    "    itk.SetOrigin(affine['origin'])\n",
    "    itk.SetDirection(affine['direction'])\n",
    "\n",
    "    sitk.WriteImage(itk, str(savePath))\n",
    "    return itk\n",
    "\n",
    "\n",
    "def info(*args, show: bool = True, **kwargs):\n",
    "    if show:\n",
    "        print(*args, **kwargs)\n",
    "\n",
    "\n",
    "def seg_simplify(seg_itk: sitk.Image) -> np.ndarray:\n",
    "    seg_ary = sitk.GetArrayFromImage(seg_itk)\n",
    "    seg_simp_ary = np.zeros_like(seg_ary, dtype=np.uint8)\n",
    "    '''\n",
    "             0,      1,    2-3,     5,    6,    13-17, 44-48,    18-41, 58-81, X\n",
    "    background, spleen, kidney, liver, stomach, lung, heart, vertebrae, rib, rili\n",
    "             0,      1,      2,     3,       4,    5,     6,         7,   8,    9\n",
    "    '''\n",
    "    seg_simp_ary[seg_ary == 1] = 1  # seg spleen\n",
    "    seg_simp_ary[(seg_ary == 2) | (seg_ary == 3)] = 2  # seg kidney\n",
    "    seg_simp_ary[seg_ary == 5] = 3  # seg liver\n",
    "    seg_simp_ary[seg_ary == 6] = 4  # seg stomach\n",
    "    seg_simp_ary[(seg_ary >= 13) & (seg_ary <= 17)] = 5  # seg lung\n",
    "    seg_simp_ary[(seg_ary >= 44) & (seg_ary <= 48)] = 6  # seg heart\n",
    "    seg_simp_ary[(seg_ary >= 18) & (seg_ary <= 41)] = 7  # seg vertebrae\n",
    "    seg_simp_ary[(seg_ary >= 58) & (seg_ary <= 81)] = 8  # seg rib\n",
    "\n",
    "    return seg_simp_ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcm_to_nifti_manual(source: Path, target: Path) -> Tuple[sitk.Image, np.ndarray]:\n",
    "    # Load all the DICOM files from a single folder into a list of 3D images and return the numpy array by simpleITK\n",
    "    # reader = sitk.ImageSeriesReader()\n",
    "    # dicom_names = reader.GetGDCMSeriesFileNames(patientDicomPath)\n",
    "    # reader.SetFileNames(dicom_names)\n",
    "    # img_itk = reader.Execute()\n",
    "    # img_3dnp = sitk.GetArrayFromImage(img_itk)\n",
    "\n",
    "    dicom_files = list(source.rglob('*.dcm'))\n",
    "    slices = [pydicom.dcmread(file) for file in dicom_files]\n",
    "    slices = [s for s in slices if s.Modality == 'CT']\n",
    "    slices.sort(key=lambda x: int(x.InstanceNumber))\n",
    "    try:\n",
    "        img_3d = np.stack([s.pixel_array for s in slices])\n",
    "    except ValueError as e:\n",
    "        if 'all input arrays must have the same shape' in str(e):\n",
    "            info(f\"pixel must have the same shape, but not on folder {source}\\nForce clip by {IMG_SIZE}\")\n",
    "            info([s.pixel_array.shape for s in slices])\n",
    "            img_3d = np.stack([np.resize(s.pixel_array, (IMG_SIZE, IMG_SIZE)) for s in slices])\n",
    "        else:\n",
    "            raise e\n",
    "    img_3d = img_3d * slices[0].RescaleSlope + slices[0].RescaleIntercept\n",
    "\n",
    "    affine3d = {\n",
    "        'spacing': (slices[0].PixelSpacing[0], slices[0].PixelSpacing[1], slices[0].SliceThickness),\n",
    "        'origin': slices[0].ImagePositionPatient,\n",
    "        'direction': (1, 0, 0, 0, 1, 0, 0, 0, -1)\n",
    "    }\n",
    "\n",
    "    img_itk = toITK(img_3d, target, affine3d)\n",
    "    return img_itk, img_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_input(source: Path, target: Path, infoLv: int = 0) -> Tuple[np.ndarray, sitk.Image, Path]:\n",
    "    if '.nii' not in target.name:\n",
    "        img_nii = target / (source.name + '.nii.gz')\n",
    "    else:\n",
    "        img_nii = target\n",
    "    if source.is_dir():\n",
    "        if not img_nii.exists():\n",
    "            try:\n",
    "                dcm_to_nifti(source, img_nii)\n",
    "                info(f'convert {source.name} folder to {img_nii.name}', show=infoLv > 0)\n",
    "                img_itk = sitk.ReadImage(str(img_nii))\n",
    "            except Exception as e:\n",
    "                info('defalut convert method failed, try manual convert method', show=infoLv > 0)\n",
    "                info(e, show=infoLv > 1)\n",
    "                img_itk, img_3d = dcm_to_nifti_manual(source, img_nii)\n",
    "                info(f'convert {source.name} folder to {img_nii.name}', show=infoLv > 0)\n",
    "        else:\n",
    "            img_itk = sitk.ReadImage(str(img_nii))\n",
    "    elif source.is_file() and '.nii' in source.name:\n",
    "        img_itk = sitk.ReadImage(str(source))\n",
    "        img_nii = source\n",
    "    else:\n",
    "        raise ValueError(f'input {source} not a valid file or folder')\n",
    "    img_3d = sitk.GetArrayFromImage(img_itk)\n",
    "    return img_3d, img_itk, img_nii\n",
    "\n",
    "\n",
    "def pre_seg_pred(img_path: Path, target: Path, gpu: bool = False, infoLv: int = 0) -> Tuple[np.ndarray, sitk.Image, Path]:\n",
    "    if '.nii' not in target.name:\n",
    "        seg_nii = target / (img_path.name + '_seg.nii.gz')\n",
    "    elif 'seg' not in target.name:\n",
    "        seg_nii = target.parent / (target.name.replace('.nii', '_seg.nii'))\n",
    "    else:\n",
    "        seg_nii = target\n",
    "    with HiddenPrints():\n",
    "        totalsegmentator(img_path, seg_nii, ml=True, fast=not gpu)\n",
    "    seg_itk = sitk.ReadImage(str(seg_nii))\n",
    "    seg_simp_ary = seg_simplify(seg_itk)\n",
    "    seg_simp_itk = toITK(seg_simp_ary, seg_nii, {\n",
    "        'spacing': seg_itk.GetSpacing(),\n",
    "        'origin': seg_itk.GetOrigin(),\n",
    "        'direction': seg_itk.GetDirection()\n",
    "    })\n",
    "    info(f'pre-segmentation is done', show=infoLv > 0)\n",
    "\n",
    "    return seg_simp_ary, seg_simp_itk, seg_nii\n",
    "\n",
    "\n",
    "def preprocess(img3d: np.ndarray,\n",
    "               seg3d: np.ndarray,\n",
    "               window: Tuple[int, int],\n",
    "               xfmComp: Callable,\n",
    "               infoLv: int = 0) -> Tuple[torch.Tensor, Tuple[int, int]]:\n",
    "    lung_slice = [i for i, ls in enumerate(seg3d) if np.sum(ls == 5) > 0]\n",
    "    lung_filter = (min(lung_slice), max(lung_slice))\n",
    "    info(f'lung filter: {lung_filter}', show=infoLv > 1)\n",
    "    img_md = img3d.copy()[lung_filter[0]:lung_filter[1] + 1]\n",
    "    img_md = np.clip(img_md, window[0], window[1])  # windowing\n",
    "    img_md = img_md.astype(np.float32)\n",
    "    img_md = (img_md - window[0]) / (window[1] - window[0])  # normalize to [0, 1]\n",
    "\n",
    "    img4d_ts = torch.stack([xfmComp(img_md[i]) for i in range(img_md.shape[0])])\n",
    "    info(f'preprocess shape: {img4d_ts.shape}', show=infoLv > 0)\n",
    "    return img4d_ts, lung_filter\n",
    "\n",
    "\n",
    "def load_model(net: torch.nn.Module, weightPath: Path, infoLv: int = 0) -> torch.nn.Module:\n",
    "    if weightPath is not None:\n",
    "        state_dict = torch.load(weightPath, map_location=torch.device('cpu'))\n",
    "        moderfied_state_dict = {}\n",
    "        for key, value in state_dict.items():\n",
    "            if key.startswith('module.'):  # 删除\"module.\"前缀\n",
    "                new_key = key[7:]\n",
    "            else:\n",
    "                new_key = key\n",
    "            moderfied_state_dict[new_key] = value\n",
    "        del state_dict\n",
    "        net.load_state_dict(moderfied_state_dict)\n",
    "        info(f'load model from {weightPath}', show=infoLv > 0)\n",
    "    return net\n",
    "\n",
    "\n",
    "def evaluate(net: torch.nn.Module,\n",
    "             img4d_ts: torch.Tensor,\n",
    "             batchSize: int = 8,\n",
    "             gpu: bool = True,\n",
    "             infoLv: int = 0) -> torch.Tensor:\n",
    "    torch.cuda.set_device(GPU_NUMBER)\n",
    "    device = torch.device(\"cuda\".format(GPU_NUMBER) if gpu else \"cpu\")\n",
    "    info(\"device\", torch.cuda.current_device(), torch.cuda.get_device_name(torch.cuda.current_device()), show=infoLv > 0)\n",
    "\n",
    "    net.to(device).eval()\n",
    "    with torch.no_grad():\n",
    "        output = torch.cat([net(img4d_ts[i:i + batchSize].to(device)) for i in range(0, img4d_ts.shape[0], batchSize)], dim=0)\n",
    "    return output\n",
    "\n",
    "\n",
    "def postprocess(output: torch.Tensor, seg3d: np.ndarray, lung_filter: Tuple[int, int], threshold: float = 0.5, infoLv: int = 0):\n",
    "    output = output.cpu()\n",
    "    output = torch.sigmoid(output)\n",
    "    output = output.numpy()\n",
    "\n",
    "    ref_seg = seg3d[lung_filter[0]:lung_filter[1] + 1]\n",
    "\n",
    "    rili_full_flat = np.zeros(ref_seg.shape, dtype=np.uint8)\n",
    "    diff_size = (IMG_SIZE - NET_SIZE) // 2\n",
    "    for i, pp in enumerate(output):\n",
    "        pc, _ = cv2.findContours(np.array(pp[0] > threshold, np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        for c in pc:\n",
    "            if cv2.contourArea(c) > SMOOTH_AREA:\n",
    "                temp = np.zeros_like(rili_full_flat[i], dtype=np.uint8)\n",
    "                cv2.fillPoly(temp, [c + diff_size], 1)\n",
    "\n",
    "                if np.sum((ref_seg[i] == 5) & temp) / np.sum(temp) > 0.9:\n",
    "                    cv2.fillPoly(rili_full_flat[i], [c + diff_size], 1)\n",
    "\n",
    "    return rili_full_flat\n",
    "\n",
    "\n",
    "def merge_pred(rili: np.ndarray, seg: np.ndarray, lung_filter: Tuple[int, int], infoLv: int = 0) -> np.ndarray:\n",
    "    rili_whole = np.zeros(seg.shape, dtype=np.uint8)\n",
    "    rili_whole[lung_filter[0]:lung_filter[1] + 1] = rili\n",
    "\n",
    "    seg[rili_whole == 1] = 9\n",
    "    return seg\n",
    "\n",
    "\n",
    "def draw(img3D: np.ndarray, msk3D: np.ndarray, savePath: Path, window=(-1000, 200)):\n",
    "    COLORS = ['#FF5733', '#4CAF50', '#4287f5', '#FFC300', '#E040FB', '#FF9933', '#5C5C5C', '#FF66CC', '#00BFFF', '#FF1493']\n",
    "    pos_pairs = []\n",
    "    for i, (x, y) in enumerate(zip(img3D, msk3D)):\n",
    "        if np.sum(y == 9) > 0:\n",
    "            pos_pairs.append((i, x, y))\n",
    "\n",
    "    d = len(pos_pairs)\n",
    "    di, dj = [[j, j + i] for j in range(d) for i in range(2) if j**2 + i * j > d][0]\n",
    "    fig = plt.figure(figsize=(min(dj * 4, 24), min(di * 4, 24)))\n",
    "    for i, (idx, img, msk) in enumerate(pos_pairs):\n",
    "        ax = fig.add_subplot(di, dj, i + 1)\n",
    "        ax.imshow(img, cmap='bone', vmin=window[0], vmax=window[1])\n",
    "        # ax.imshow(msk, alpha=.3, cmap='rainbow')\n",
    "        for v in range(1, 10):\n",
    "            pc, _ = cv2.findContours(np.array(msk == v, np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            for c in pc:\n",
    "                plt.plot(c[:, 0, 0], c[:, 0, 1], color=COLORS[v])\n",
    "        ax.set_title(f\"slice {idx}, area {np.sum(msk)}\")\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(savePath))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference2itk(source: str | Path,\n",
    "                  targetFolder: str | Path,\n",
    "                  modelWeight: str | Path,\n",
    "                  type: str = 'nrrd',\n",
    "                  batchSize: int = BATCH_SIZE,\n",
    "                  window: Tuple[int, int] = HU_CLIP,\n",
    "                  xfmComp: Callable = XFM_COMP,\n",
    "                  net: torch.nn.Module = NET,\n",
    "                  preview: bool = False,\n",
    "                  infoLv: int = 1):\n",
    "    start = time.time()\n",
    "\n",
    "    if isinstance(source, str):\n",
    "        source = Path(source)\n",
    "    if isinstance(targetFolder, str):\n",
    "        targetFolder = Path(targetFolder)\n",
    "        targetFolder.mkdir(parents=True, exist_ok=True)\n",
    "    if isinstance(modelWeight, str):\n",
    "        modelWeight = Path(modelWeight)\n",
    "\n",
    "    img3d, img_itk, img_nii = deal_input(source=source, target=targetFolder, infoLv=infoLv)\n",
    "    seg3d, seg_itk, seg_nii = pre_seg_pred(img_nii, target=targetFolder, gpu=torch.cuda.is_available(), infoLv=infoLv)\n",
    "    img4dts, lfilter = preprocess(img3d, seg3d, window=window, xfmComp=xfmComp, infoLv=infoLv)\n",
    "    net = load_model(net, modelWeight, infoLv=infoLv)\n",
    "    rili_raw = evaluate(net, img4dts, batchSize=batchSize, gpu=torch.cuda.is_available(), infoLv=infoLv)\n",
    "    rili = postprocess(rili_raw, seg3d, lfilter, threshold=THRESHOLD, infoLv=infoLv)\n",
    "    seg_rili = merge_pred(rili, seg3d, lfilter, infoLv=infoLv)\n",
    "\n",
    "    rili_nii = targetFolder / (source.name + '_rili.nii.gz')\n",
    "    seg_rili_itk = toITK(seg_rili, rili_nii, {\n",
    "        'spacing': seg_itk.GetSpacing(),\n",
    "        'origin': seg_itk.GetOrigin(),\n",
    "        'direction': seg_itk.GetDirection()\n",
    "    })\n",
    "\n",
    "    if type == 'nrrd':\n",
    "        os.remove(img_nii)\n",
    "        os.remove(seg_nii)\n",
    "        os.remove(rili_nii)\n",
    "        sitk.WriteImage(img_itk, targetFolder / (source.name + '.nrrd'))\n",
    "        sitk.WriteImage(seg_itk, targetFolder / (source.name + 'seg.nrrd'))\n",
    "        sitk.WriteImage(seg_rili_itk, targetFolder / (source.name + 'rili.seg.nrrd'))\n",
    "\n",
    "    if preview:\n",
    "        draw(img3d, seg_rili, targetFolder / (source.name + '_seg.png'))\n",
    "        info(f'Preview saved: {source.name} -> {targetFolder / (source.name + \"_seg.png\")}')\n",
    "\n",
    "    info(f'Inference finished: {source.name} -> {targetFolder}, time cost: {time.time() - start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert 000218422H_20191128 folder to 000218422H_20191128.nii.gz\n",
      "pre-segmentation is done\n",
      "preprocess shape: torch.Size([50, 1, 448, 448])\n",
      "load model from /root/projs/rili/RILI-2019-2020/expA/0.0242_164.pth\n",
      "device 0 NVIDIA GeForce RTX 3090\n",
      "Preview saved: 000218422H_20191128 -> tmp/000218422H_20191128_seg.png\n",
      "Inference finished: 000218422H_20191128 -> tmp, time cost: 57.27s\n"
     ]
    }
   ],
   "source": [
    "msk = inference2itk(\n",
    "    modelWeight='/root/projs/rili/RILI-2019-2020/expA/0.0242_164.pth',\n",
    "    source=\n",
    "    '/root/projs/rili/RILI-2019-2020/RP-2019-46p111ct/000218422H_20191128',  #'D:/irene2023_share/20230711/001163511D/1.2.840.113817.20230411120100.1200116351194.85938009287',\n",
    "    targetFolder='./tmp/',\n",
    "    preview=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
